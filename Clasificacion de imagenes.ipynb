{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tittle](img/universidad_politecnica_salesiana.png)\n",
    "# <center>Systems Engineering Career</center><br><center>Artificial Intelligence II</center><br><center>Neural Networks with Scikit-Learn: Shape Recognition</center>\n",
    "\n",
    "**By: Jorge Sanisaca**\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This book presents a project on the main aspects to create, train and validate articular neural networks in Ptython with Scikit-Learn. Taking into account multilayer Perceptron as a tool to perform the classification.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "We will need to have the following libraries installed:\n",
    "\n",
    "1. Python (versiones >=2.7 o >=3.3)\n",
    "2. Numpy >= 1.16.5\n",
    "3. SciPy >= 0.13.3\n",
    "4. Scikit-Learn 0.21.3\n",
    "5. Pandas >= 0.25.1\n",
    "6. viznet\n",
    "\n",
    "## Installations\n",
    "\n",
    "    pip install -U scikit-learn\n",
    "    pip install viznet\n",
    "    pip install pandas\n",
    "\n",
    "## Problema\n",
    "\n",
    "The corpus represents a set of data a set of data of the weighted means of the pixel intensities of the images already processed with <a href='https://opencv.org/'>OpenCV</a>, where each column represents the moments that are invariable for the translation, the scale and the rotation that are called **Hu Moments** which are a set of 7 numbers calculated using central moments that are invariable for image transformations.\n",
    "\n",
    "The objective is to design and train a neural network that allows classifying samples based on the characteristics of these images.\n",
    "\n",
    "## Process\n",
    "\n",
    "### Data reading\n",
    "\n",
    "As a first step we will proceed to load the data using the <a href='https://pandas.pydata.org/'>Pandas</a> library. To do this, we will use the read_csv method and specify the separator and the names we want to be loaded when reading the file.\n",
    "\n",
    "It is important to note that the read_csv method returns a dataframe object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>Fichero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.161964</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>4.605700e-05</td>\n",
       "      <td>2.705150e-06</td>\n",
       "      <td>3.012040e-11</td>\n",
       "      <td>5.001100e-09</td>\n",
       "      <td>-2.122570e-12</td>\n",
       "      <td>train/apple-1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.236366</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>1.099700e-02</td>\n",
       "      <td>7.623680e-05</td>\n",
       "      <td>-3.180690e-08</td>\n",
       "      <td>6.968630e-07</td>\n",
       "      <td>-6.213690e-08</td>\n",
       "      <td>train/device8-3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.159180</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2.945610e-10</td>\n",
       "      <td>2.174170e-14</td>\n",
       "      <td>5.484940e-26</td>\n",
       "      <td>5.958650e-17</td>\n",
       "      <td>4.340170e-27</td>\n",
       "      <td>train/device9-20.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.187058</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>5.355570e-05</td>\n",
       "      <td>1.366400e-05</td>\n",
       "      <td>-6.237880e-11</td>\n",
       "      <td>4.878330e-07</td>\n",
       "      <td>3.643300e-10</td>\n",
       "      <td>train/Misk-9.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.176794</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>6.260300e-07</td>\n",
       "      <td>1.835560e-09</td>\n",
       "      <td>-1.577080e-17</td>\n",
       "      <td>8.472220e-13</td>\n",
       "      <td>-6.019110e-17</td>\n",
       "      <td>train/device1-10.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1        f2            f3            f4            f5            f6  \\\n",
       "0  0.161964  0.000004  4.605700e-05  2.705150e-06  3.012040e-11  5.001100e-09   \n",
       "1  0.236366  0.000105  1.099700e-02  7.623680e-05 -3.180690e-08  6.968630e-07   \n",
       "2  0.159180  0.000008  2.945610e-10  2.174170e-14  5.484940e-26  5.958650e-17   \n",
       "3  0.187058  0.003204  5.355570e-05  1.366400e-05 -6.237880e-11  4.878330e-07   \n",
       "4  0.176794  0.000002  6.260300e-07  1.835560e-09 -1.577080e-17  8.472220e-13   \n",
       "\n",
       "             f7               Fichero  \n",
       "0 -2.122570e-12     train/apple-1.png  \n",
       "1 -6.213690e-08   train/device8-3.png  \n",
       "2  4.340170e-27  train/device9-20.png  \n",
       "3  3.643300e-10      train/Misk-9.png  \n",
       "4 -6.019110e-17  train/device1-10.png  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "datos = pd.read_csv('corpus/datos.csv', sep=\";\")\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the name of the image\n",
    "\n",
    "As we can see the dataframe _data_ generated in the previous step we can see that the column _File_ contains the path where the image is located, however for this processing we need to stay only with the name or type of image for this we will cut the column in order to stay alone with the name of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>Fichero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.161964</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>4.605700e-05</td>\n",
       "      <td>2.705150e-06</td>\n",
       "      <td>3.012040e-11</td>\n",
       "      <td>5.001100e-09</td>\n",
       "      <td>-2.122570e-12</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.236366</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>1.099700e-02</td>\n",
       "      <td>7.623680e-05</td>\n",
       "      <td>-3.180690e-08</td>\n",
       "      <td>6.968630e-07</td>\n",
       "      <td>-6.213690e-08</td>\n",
       "      <td>device8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.159180</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2.945610e-10</td>\n",
       "      <td>2.174170e-14</td>\n",
       "      <td>5.484940e-26</td>\n",
       "      <td>5.958650e-17</td>\n",
       "      <td>4.340170e-27</td>\n",
       "      <td>device9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.187058</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>5.355570e-05</td>\n",
       "      <td>1.366400e-05</td>\n",
       "      <td>-6.237880e-11</td>\n",
       "      <td>4.878330e-07</td>\n",
       "      <td>3.643300e-10</td>\n",
       "      <td>Misk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.176794</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>6.260300e-07</td>\n",
       "      <td>1.835560e-09</td>\n",
       "      <td>-1.577080e-17</td>\n",
       "      <td>8.472220e-13</td>\n",
       "      <td>-6.019110e-17</td>\n",
       "      <td>device1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1        f2            f3            f4            f5            f6  \\\n",
       "0  0.161964  0.000004  4.605700e-05  2.705150e-06  3.012040e-11  5.001100e-09   \n",
       "1  0.236366  0.000105  1.099700e-02  7.623680e-05 -3.180690e-08  6.968630e-07   \n",
       "2  0.159180  0.000008  2.945610e-10  2.174170e-14  5.484940e-26  5.958650e-17   \n",
       "3  0.187058  0.003204  5.355570e-05  1.366400e-05 -6.237880e-11  4.878330e-07   \n",
       "4  0.176794  0.000002  6.260300e-07  1.835560e-09 -1.577080e-17  8.472220e-13   \n",
       "\n",
       "             f7  Fichero  \n",
       "0 -2.122570e-12    apple  \n",
       "1 -6.213690e-08  device8  \n",
       "2  4.340170e-27  device9  \n",
       "3  3.643300e-10     Misk  \n",
       "4 -6.019110e-17  device1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos['Fichero'] = datos['Fichero'].str.split('/').str[1]\n",
    "datos['Fichero'] = datos['Fichero'].str.split('-').str[0]\n",
    "\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also analyze the corpus using the function described by Pandas. The values that we can obtain from each variable are the following:\n",
    "\n",
    "* count\n",
    "* mean\n",
    "* standard deviation (std)\n",
    "* min\n",
    "* Percentiles, which are the values that are between 25%, 50%, 75%.\n",
    "* max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>f1</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>0.317706</td>\n",
       "      <td>0.200907</td>\n",
       "      <td>0.159180</td>\n",
       "      <td>1.991075e-01</td>\n",
       "      <td>2.493580e-01</td>\n",
       "      <td>3.419902e-01</td>\n",
       "      <td>1.550570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f2</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>0.083006</td>\n",
       "      <td>0.224974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.028440e-03</td>\n",
       "      <td>1.621600e-02</td>\n",
       "      <td>5.150630e-02</td>\n",
       "      <td>2.162990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f3</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>0.013257</td>\n",
       "      <td>0.047733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.764270e-04</td>\n",
       "      <td>1.070585e-03</td>\n",
       "      <td>5.188960e-03</td>\n",
       "      <td>0.942444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f4</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>0.005712</td>\n",
       "      <td>0.023760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.288693e-05</td>\n",
       "      <td>1.352400e-04</td>\n",
       "      <td>8.837387e-04</td>\n",
       "      <td>0.327414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f5</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.006923</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-5.286663e-14</td>\n",
       "      <td>4.632130e-09</td>\n",
       "      <td>3.788562e-07</td>\n",
       "      <td>0.181674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f6</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>0.003449</td>\n",
       "      <td>0.017738</td>\n",
       "      <td>-0.004850</td>\n",
       "      <td>-7.138183e-09</td>\n",
       "      <td>2.447115e-06</td>\n",
       "      <td>8.138190e-05</td>\n",
       "      <td>0.203791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f7</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>-0.003646</td>\n",
       "      <td>-9.976037e-09</td>\n",
       "      <td>2.349400e-13</td>\n",
       "      <td>1.558542e-08</td>\n",
       "      <td>0.008558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count      mean       std       min           25%           50%  \\\n",
       "f1  1120.0  0.317706  0.200907  0.159180  1.991075e-01  2.493580e-01   \n",
       "f2  1120.0  0.083006  0.224974  0.000000  2.028440e-03  1.621600e-02   \n",
       "f3  1120.0  0.013257  0.047733  0.000000  2.764270e-04  1.070585e-03   \n",
       "f4  1120.0  0.005712  0.023760  0.000000  2.288693e-05  1.352400e-04   \n",
       "f5  1120.0  0.000791  0.006923 -0.000156 -5.286663e-14  4.632130e-09   \n",
       "f6  1120.0  0.003449  0.017738 -0.004850 -7.138183e-09  2.447115e-06   \n",
       "f7  1120.0  0.000003  0.000307 -0.003646 -9.976037e-09  2.349400e-13   \n",
       "\n",
       "             75%       max  \n",
       "f1  3.419902e-01  1.550570  \n",
       "f2  5.150630e-02  2.162990  \n",
       "f3  5.188960e-03  0.942444  \n",
       "f4  8.837387e-04  0.327414  \n",
       "f5  3.788562e-07  0.181674  \n",
       "f6  8.138190e-05  0.203791  \n",
       "f7  1.558542e-08  0.008558  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the last column contains text strings that describe the type of image. To do this, we can use the map function provided by Pandas and replace the strings with numerical values that can be understood by the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>Fichero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.161964</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>4.605700e-05</td>\n",
       "      <td>2.705150e-06</td>\n",
       "      <td>3.012040e-11</td>\n",
       "      <td>5.001100e-09</td>\n",
       "      <td>-2.122570e-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.236366</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>1.099700e-02</td>\n",
       "      <td>7.623680e-05</td>\n",
       "      <td>-3.180690e-08</td>\n",
       "      <td>6.968630e-07</td>\n",
       "      <td>-6.213690e-08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.159180</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2.945610e-10</td>\n",
       "      <td>2.174170e-14</td>\n",
       "      <td>5.484940e-26</td>\n",
       "      <td>5.958650e-17</td>\n",
       "      <td>4.340170e-27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.187058</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>5.355570e-05</td>\n",
       "      <td>1.366400e-05</td>\n",
       "      <td>-6.237880e-11</td>\n",
       "      <td>4.878330e-07</td>\n",
       "      <td>3.643300e-10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.176794</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>6.260300e-07</td>\n",
       "      <td>1.835560e-09</td>\n",
       "      <td>-1.577080e-17</td>\n",
       "      <td>8.472220e-13</td>\n",
       "      <td>-6.019110e-17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1        f2            f3            f4            f5            f6  \\\n",
       "0  0.161964  0.000004  4.605700e-05  2.705150e-06  3.012040e-11  5.001100e-09   \n",
       "1  0.236366  0.000105  1.099700e-02  7.623680e-05 -3.180690e-08  6.968630e-07   \n",
       "2  0.159180  0.000008  2.945610e-10  2.174170e-14  5.484940e-26  5.958650e-17   \n",
       "3  0.187058  0.003204  5.355570e-05  1.366400e-05 -6.237880e-11  4.878330e-07   \n",
       "4  0.176794  0.000002  6.260300e-07  1.835560e-09 -1.577080e-17  8.472220e-13   \n",
       "\n",
       "             f7  Fichero  \n",
       "0 -2.122570e-12        0  \n",
       "1 -6.213690e-08        1  \n",
       "2  4.340170e-27        2  \n",
       "3  3.643300e-10        3  \n",
       "4 -6.019110e-17        4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nombres = datos['Fichero'].unique().tolist()\n",
    "# print(nombres)\n",
    "datos['Fichero']=datos['Fichero'].map({'apple':0, 'device8':1, 'device9':2, 'Misk':3, 'device1':4, 'carriage':5, \n",
    "                                       'device3':6, 'fly':7, 'cup':8, 'car':9, 'camel':10, 'Bone':11, 'turtle':12, \n",
    "                                       'bat':13, 'cellular_phone':14, 'pocket':15, 'device4':16, 'teddy':17, 'frog':18, \n",
    "                                       'lizzard':19, 'cattle':20, 'spoon':21, 'guitar':22, 'fountain':23, 'octopus':24, \n",
    "                                       'bird':25, 'ray':26, 'spring':27, 'chopper':28, 'horse':29, 'dog':30, 'hat':31, \n",
    "                                       'personal_car':32, 'butterfly':33, 'device5':34, 'brick':35, 'device0':36, 'key':37, \n",
    "                                       'crown':38, 'fish':39, 'shoe':40, 'Comma':41, 'fork':42, 'HCircle':43, 'device7':44, \n",
    "                                       'lmfish':45, 'watch':46, 'beetle':47, 'bell':48, 'rat':49, 'elephant':50, 'deer':51, \n",
    "                                       'hammer':52, 'jar':53, 'Heart':54, 'flatfish':55, 'sea_snake':56, 'horseshoe':57, \n",
    "                                       'Glas':58, 'tree':59, 'stef':60, 'truck':61, 'children':62, 'face':63, 'bottle':64, \n",
    "                                       'pencil':65, 'chicken':66, 'device2':67, 'device6':68, 'classic':69})\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Design\n",
    "\n",
    "As a next point, we will design a neural network (multilayer perceptron classifier) to learn how to distinguish between different types of images.\n",
    "\n",
    "The artificial neural network will have the following characteristics:\n",
    "\n",
    "* Entradas: 7\n",
    "* Número de capas: 70\n",
    "* Neuronas en la capa oculta: 10\n",
    "* Neuronas en la capa de salida: 70\n",
    "\n",
    "### Preprocessing of data and generation of training and testing corpus\n",
    "\n",
    "As a previous step to train the neural network, it is essential to preprocess the data (scale, change formats, etc.), since otherwise optimal results will not be obtained in the classification process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.77011187, -0.37188139, -0.26469383, -0.23496323, -0.11352916,\n",
       "        -0.19431574, -0.00430886],\n",
       "       [ 3.671591  ,  3.7595119 ,  1.32166184,  0.12063621, -0.0890712 ,\n",
       "         0.16902901, -0.42689269],\n",
       "       [-0.67212809, -0.36312184, -0.25866301, -0.23438666, -0.11352907,\n",
       "        -0.19434883, -0.00431089],\n",
       "       [-0.39786821, -0.24949913, -0.26070641, -0.23268111, -0.11352843,\n",
       "        -0.19409487, -0.00431634],\n",
       "       [ 0.21865912, -0.36944091, -0.25543829, -0.23014452, -0.1135313 ,\n",
       "        -0.19421029, -0.00423988],\n",
       "       [ 0.42812264,  0.10609515, -0.15276291, -0.07138302, -0.11099275,\n",
       "        -0.12594532, -0.00854249]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from viznet import connecta2a, node_sequence, NodeBrush, EdgeBrush, DynamicShow\n",
    "# We import the function to scale the values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "# We import the function to separate test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We create variables with the parameters that the network will have\n",
    "entradas = 7\n",
    "neuronas_capa_oculta = 100\n",
    "neuronas_capa_salida = 70\n",
    "\n",
    "# We separate the input data into a variable, for this we generate a copy of the dataframe\n",
    "# removing the last column of the corpus (the one with the types of images)\n",
    "X=datos.drop('Fichero',axis=1)\n",
    "\n",
    "# We proceed in the same way, but in this case to generate an arrangement that has the desired outputs\n",
    "d=datos['Fichero']\n",
    "\n",
    "# We show the first data on the screen with the 'head' function\n",
    "X.head()\n",
    "d.head()\n",
    "\n",
    "X_train, X_test, d_train, d_test = train_test_split(X,d,train_size=0.80,random_state=0,stratify=d)\n",
    "\n",
    "# We perform OneHotEncoding to have 70 outputs instead of 1 and then perform a dataframe with pandas\n",
    "dat_dict=datos.T.to_dict().values()\n",
    "vectorizer = DV(sparse = False)\n",
    "vectorizer.fit(dat_dict)\n",
    "dat= vectorizer.transform(dat_dict)\n",
    "dat=pd.DataFrame(dat)\n",
    "\n",
    "# We generate an object to scale the values\n",
    "scaler=StandardScaler()\n",
    "\n",
    "# Adjust only in training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Escalamos el corpus de entrenamiento\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n",
    "# We visualize the first 7 rows of data\n",
    "X_train[1:7,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100, 70), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=10000,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=None, shuffle=True, solver='lbfgs',\n",
      "              tol=1e-15, validation_fraction=0.1, verbose=True,\n",
      "              warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanix\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100, 70), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=10000,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='lbfgs',\n",
       "              tol=1e-15, validation_fraction=0.1, verbose=True,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We import the Perceptron Multilayer for Classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# We create the neural network\n",
    "mlp=MLPClassifier(solver = 'lbfgs', activation='tanh', verbose=True, alpha=1e-4, tol=1e-15, max_iter=10000, \\\n",
    "                  hidden_layer_sizes=(neuronas_capa_oculta, neuronas_capa_salida))\n",
    "\n",
    "print(mlp)\n",
    "# We carry out the training process\n",
    "mlp.fit(X_train,d_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and evaluation of the network\n",
    "\n",
    "The last step is to evaluate the operation of the network. To do this, we will determine how it behaves in prediction tasks with the test part (X_test, d_test):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusion\n",
      "\n",
      "[[2 0 0 ... 0 0 0]\n",
      " [0 4 0 ... 0 0 0]\n",
      " [0 0 1 ... 1 1 0]\n",
      " ...\n",
      " [0 0 1 ... 2 0 0]\n",
      " [0 0 2 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 3]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       1.00      1.00      1.00         4\n",
      "           2       0.20      0.33      0.25         3\n",
      "           3       0.33      0.67      0.44         3\n",
      "           4       1.00      1.00      1.00         3\n",
      "           5       0.75      1.00      0.86         3\n",
      "           6       1.00      0.50      0.67         4\n",
      "           7       0.50      0.33      0.40         3\n",
      "           8       1.00      0.67      0.80         3\n",
      "           9       0.67      0.50      0.57         4\n",
      "          10       0.00      0.00      0.00         3\n",
      "          11       1.00      0.33      0.50         3\n",
      "          12       0.50      0.25      0.33         4\n",
      "          13       0.60      1.00      0.75         3\n",
      "          14       0.33      0.33      0.33         3\n",
      "          15       0.20      0.33      0.25         3\n",
      "          16       1.00      1.00      1.00         3\n",
      "          17       1.00      1.00      1.00         3\n",
      "          18       1.00      0.33      0.50         3\n",
      "          19       0.50      0.67      0.57         3\n",
      "          20       0.33      0.33      0.33         3\n",
      "          21       1.00      0.50      0.67         4\n",
      "          22       0.33      0.67      0.44         3\n",
      "          23       0.50      0.50      0.50         4\n",
      "          24       0.00      0.00      0.00         4\n",
      "          25       0.00      0.00      0.00         3\n",
      "          26       1.00      0.33      0.50         3\n",
      "          27       0.50      1.00      0.67         3\n",
      "          28       1.00      1.00      1.00         3\n",
      "          29       1.00      0.67      0.80         3\n",
      "          30       1.00      0.33      0.50         3\n",
      "          31       0.20      0.33      0.25         3\n",
      "          32       0.50      0.67      0.57         3\n",
      "          33       0.40      0.67      0.50         3\n",
      "          34       0.50      1.00      0.67         3\n",
      "          35       0.50      0.67      0.57         3\n",
      "          36       1.00      0.75      0.86         4\n",
      "          37       1.00      0.33      0.50         3\n",
      "          38       0.14      0.25      0.18         4\n",
      "          39       0.00      0.00      0.00         3\n",
      "          40       0.00      0.00      0.00         3\n",
      "          41       0.25      0.33      0.29         3\n",
      "          42       0.50      0.33      0.40         3\n",
      "          43       0.00      0.00      0.00         3\n",
      "          44       0.80      1.00      0.89         4\n",
      "          45       0.50      0.33      0.40         3\n",
      "          46       0.33      0.33      0.33         3\n",
      "          47       0.25      0.25      0.25         4\n",
      "          48       0.75      1.00      0.86         3\n",
      "          49       0.60      1.00      0.75         3\n",
      "          50       0.75      1.00      0.86         3\n",
      "          51       1.00      0.67      0.80         3\n",
      "          52       0.75      1.00      0.86         3\n",
      "          53       0.75      1.00      0.86         3\n",
      "          54       0.50      0.67      0.57         3\n",
      "          55       1.00      1.00      1.00         3\n",
      "          56       0.67      0.67      0.67         3\n",
      "          57       0.00      0.00      0.00         3\n",
      "          58       1.00      0.50      0.67         4\n",
      "          59       0.00      0.00      0.00         3\n",
      "          60       1.00      0.67      0.80         3\n",
      "          61       1.00      1.00      1.00         4\n",
      "          62       1.00      1.00      1.00         3\n",
      "          63       1.00      1.00      1.00         3\n",
      "          64       0.80      1.00      0.89         4\n",
      "          65       0.40      0.67      0.50         3\n",
      "          66       0.25      0.33      0.29         3\n",
      "          67       0.50      0.67      0.57         3\n",
      "          68       0.00      0.00      0.00         3\n",
      "          69       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.58       224\n",
      "   macro avg       0.59      0.58      0.55       224\n",
      "weighted avg       0.60      0.58      0.56       224\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanix\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#print(d_test.value_counts())\n",
    "\n",
    "prediccion = mlp.predict(X_test)\n",
    "print('Matriz de Confusion\\n')\n",
    "print(confusion_matrix(d_test, prediccion))\n",
    "print('\\n')\n",
    "\n",
    "print(classification_report(d_test, prediccion))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
